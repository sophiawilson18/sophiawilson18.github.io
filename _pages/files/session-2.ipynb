{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7abb67ba-a521-4c75-8726-212c45352d7a",
   "metadata": {},
   "source": [
    "# CHILI Challenge\n",
    "\n",
    "### Chemically-Informed Large-scale Inorganic Nano-materials Dataset for Advancing Graph Machine Learning\n",
    "\n",
    "* New (unpublished) dataset for materials design\n",
    "* Predict crystal type, from the structure\n",
    "* $g_\\theta(\\cdot): G \\rightarrow Y$\n",
    "* Node features: $G_i: (X_i \\in \\mathbb{R}^{N_i\\times F}, A_i \\in \\{0,1\\}^{N_i\\times N_i})$\n",
    "* crystal_type: $Y = [0,1]^{C}$\n",
    "* Crystal types belong to ['AntiFluorite', 'CadmiumChloride', 'CadmiumIodide', 'CaesiumChloride', 'Fluorite', 'NickelArsenide', 'RheniumTrioxide',\n",
    "       'RockSalt', 'Rutile', 'Spinel', 'Wurtzite', 'ZincBlende']\n",
    "  \n",
    "  ![Crystal Types](crystal_type.png \"Target Crystal Types\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd8c104-b18f-4d53-91af-d50838e2c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get dataset\n",
    "from torch_geometric.data import download_url, extract_zip\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_networkx\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import os\n",
    "from torch_geometric.seed import seed_everything\n",
    "from torcheval.metrics import MulticlassF1Score, MulticlassAccuracy\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import pdb\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e84b8e-d243-46c8-80a5-6cbea0b4ff7e",
   "metadata": {},
   "source": [
    "### Download the preprocessd data\n",
    "* Data is stored on a remote server\n",
    "* Download it, unzip it!\n",
    "* This has to be done only once!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23378e-fc6c-44fa-8319-99aa8a88d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = './Data'\n",
    "if not Path(data_loc).exists():\n",
    "    Path(data_loc).mkdir()\n",
    "else:\n",
    "    print(data_loc, 'exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259bc31-bf2e-4604-afe1-1af491d56de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './Results'\n",
    "if not Path(save_dir).exists():\n",
    "    Path(save_dir).mkdir()\n",
    "else:\n",
    "    print(save_dir, 'exists!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1736a92b-446f-42d1-b054-1a3ce3284c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://sid.erda.dk/share_redirect/h7plnJoaYR/CHILI-Challenge.zip'\n",
    "# path = download_url(url,)\n",
    "dataset_name = 'CHILI-Challenge'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ffb91-e122-494e-91fc-642bbe94d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(data_loc+'/'+dataset_name+'.zip').exists():\n",
    "    print('Data not locally found. Downloading...')\n",
    "    path = download_url(url,data_loc)\n",
    "    print('Extracting data...')\n",
    "    extract_zip(path, data_loc)\n",
    "    print('Done!')\n",
    "else:\n",
    "    print('Data found at '+data_loc)\n",
    "    data_loc += '/'+dataset_name\n",
    "    print(os.listdir(data_loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61139de1-2f45-4f01-b94b-c7c2635b99d5",
   "metadata": {},
   "source": [
    "## Load the processed data and investigate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfe95b0-f10d-4785-b09f-ef8b96ea6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.load(data_loc+'/train.pt')\n",
    "valid_set = torch.load(data_loc+'/valid.pt')\n",
    "test_set = torch.load(data_loc+'/test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dd0024-67c3-4955-a523-1e37c4e18696",
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrain = len(train_set)\n",
    "nValid = len(valid_set)\n",
    "nTest = len(test_set)\n",
    "print('nTrain: %d, nValid: %d, nTest: %d'%(nTrain,nValid,nTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa1772-680f-48d0-9d5f-c4eb4ec415c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data point \n",
    "sample = train_set[2]\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e3f94-552f-4142-8c70-1def2340464e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic visualization using networkx\n",
    "# for more accurate visualization check out https://jp-minerals.org/vesta/en/download.html\n",
    "import networkx as nx\n",
    "g = to_networkx(sample, to_undirected=True)\n",
    "nx.draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30be1e7a-5e33-4dd7-8d4a-ba13f8851675",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.scatter(sample.pos_abs[:,0],sample.pos_abs[:,1],sample.pos_abs[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7866f6-6944-45aa-b64a-19d42e9d0e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipympl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4de4067-e94a-40a5-90b6-ebde7f3cb303",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class distributions\n",
    "train_labels = np.array([d.y['crystal_type'] for d in train_set])\n",
    "crystal_types = np.unique(train_labels)\n",
    "crystal_type_count = np.array([sum(train_labels==c) for c in crystal_types])\n",
    "distribution = crystal_type_count/nTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9fdcf7-e46a-4b3c-a0ee-2c6b19bc8266",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(crystal_types,crysta_type_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87b12f2-de91-4998-9485-e10c1143e4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num node distributions\n",
    "train_nodes = [d.x.shape[0] for d in train_set]\n",
    "plt.hist(train_nodes,orientation='horizontal')\n",
    "print('Min. num of nodes: %d'%(np.min(train_nodes)))\n",
    "print('Max. num of nodes: %d'%(np.max(train_nodes)))\n",
    "print('Mean num of nodes: %d'%(np.mean(train_nodes)))\n",
    "print('Median num of nodes: %d'%(np.median(train_nodes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c75b66b-6917-47e1-9d01-79308a307787",
   "metadata": {},
   "source": [
    "## Simple basline is to randomly guess the labels\n",
    "Let us implement a random guessing baseline based on training set distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e23b62-b2fe-4673-a45b-0309ce7f1455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random guessing baseline\n",
    "valid_labels_rand = torch.Tensor(np.random.choice(np.arange(0, 12), size=318, p=distribution))\n",
    "valid_labels = torch.Tensor(([d.y['crystal_type_number'] for d in valid_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1affbdc-9f56-4d6c-a66e-265f762da383",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_acc = sum(valid_labels_rand == valid_labels)/nValid\n",
    "print(val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2452508-ba5f-4c7c-9b90-ee64ae478669",
   "metadata": {},
   "source": [
    "## Another baseline method using GCNs\n",
    "* Don't be disappointed if it does not do better than random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca3d19a-c8c7-426e-ba75-ca8e57bcf47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make a pytorch-geometric dataloader\n",
    "B = 16\n",
    "train_loader = DataLoader(train_set,batch_size=B)\n",
    "valid_loader = DataLoader(valid_set,batch_size=B)\n",
    "test_loader = DataLoader(test_set,batch_size=B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4b606b-f426-4f95-9098-4fb7babd8b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load GCN model from pyg\n",
    "from torch_geometric.nn.models import GCN\n",
    "from torch_geometric.nn import global_mean_pool, Linear, global_add_pool, global_max_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb66691-f3b2-4182-8250-82918ef5a9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "lr = 1e-3\n",
    "patience = 5\n",
    "n_classes = len(crystal_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870eee00-5aca-44f5-a33b-a73e98bb1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a GCN model\n",
    "model = GCN(in_channels=7,hidden_channels=32,num_layers=4,\n",
    "            out_channels=64)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), \n",
    "                             lr=lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65fc227-20a1-49d2-b7af-6650aa5cb8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a forward pass that uses the GCN layer to \n",
    "# perform graph level classification\n",
    "\n",
    "def forward_pass(data, out_dim=n_classes):\n",
    "    out = model.forward(x=torch.cat((data.x, data.pos_abs),dim=1), \\\n",
    "                        edge_index=data.edge_index)\n",
    "    \n",
    "    out = torch.cat((global_mean_pool(out, data.batch), \\\n",
    "                     global_add_pool(out, data.batch), \\\n",
    "                     global_max_pool(out, data.batch)), dim=1)\n",
    "    \n",
    "    middle_dim = (out.size(-1) + out_dim) // 2\n",
    "    out = F.relu(Linear(out.size(-1), middle_dim).to(device)(out))\n",
    "    out = Linear(middle_dim, out_dim).to(device)(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd94a55b-ff87-40e3-a7b7-84a44960597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss=0\n",
    "    for data in tqdm(train_loader):\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = forward_pass(data)\n",
    "        target = torch.Tensor(data.y['crystal_type_number'],device=device).long()\n",
    "        loss = criterion(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    train_loss =  total_loss/len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    error = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        MC_Acc = MulticlassAccuracy(num_classes=n_classes)\n",
    "        for data in valid_loader:\n",
    "            data = data.to(device)\n",
    "            out = forward_pass(data)\n",
    "            _, predicted = torch.max(out.data,1)\n",
    "            target = torch.Tensor(data.y['crystal_type_number'],device=device).long()\n",
    "            MC_Acc.update(predicted,target)\n",
    "\n",
    "\n",
    "            val_error = torch.tensor(0)\n",
    "            val_acc = MC_Acc.compute()\n",
    "\n",
    "            # Save model if validation accuracy is improved\n",
    "            if epoch == 0:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save({\n",
    "                    'epoch': epoch+1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    },\n",
    "                    f\"{save_dir}/best.pt\"\n",
    "                    )\n",
    "            elif val_acc > best_val_acc:\n",
    "                patience = 0\n",
    "                torch.save({'epoch': epoch+1,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),},\n",
    "                    f\"{save_dir}/best.pt\")\n",
    "                best_val_acc = val_acc\n",
    "            else:\n",
    "                patience += 1\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val F1-score: {val_f1:.4f}', flush=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba7777b-5d1e-45bc-a62e-8bc52eb0cfa8",
   "metadata": {},
   "source": [
    "### Use the final converged model to predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ceb5f-e900-4e1d-a760-63bf8d14839f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"{save_dir}/best.pt\")\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc7b7e3-c556-4881-965c-f3155056d9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model and predict on test set\n",
    "import time \n",
    "timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23afc746-1e72-4b84-9459-cb62770a9cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model and predict on test set\n",
    "import time \n",
    "timestamp = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "test_id = [d.id for d in test_set]\n",
    "results = pd.DataFrame(columns=['id','predicted_label'],index=np.arange(nTest))\n",
    "results.id = test_id\n",
    "\n",
    "with torch.no_grad():    \n",
    "    for data in test_loader:\n",
    "        data = data.to(device)\n",
    "        out = forward_pass(data)\n",
    "        _, predicted = torch.max(out.data,1)\n",
    "        results.loc[results.id.isin(data.id),'predicted_label'] = predicted\n",
    "\n",
    "results.to_csv(f\"{save_dir}/results_\"+timestamp+\".csv\",index=False)\n",
    "print(\"Saved results to \"+f\"{save_dir}/results_\"+timestamp+\".csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
